# Dynamical Edge System Configuration

system:
  simulation_mode: false
  log_level: "INFO"

safety:
  stop_dist: 1.5
  sensitivity: 0.8

cameras:
  rtsp_url: "rtsp://192.168.1.100:554/stream"
  
models:
  paligemma_path: "models/paligemma"

# =============================================================================
# Compute Budget - Jetson Thor (Blackwell Architecture)
# =============================================================================
# Peak Compute by Precision:
#   FP4/INT4:  2070 TFLOPS (quantized inference)
#   FP8:       275 TFLOPS  (mixed precision)
#   FP16:      137 TFLOPS  (half precision)
#   FP32:      68 TFLOPS   (full precision)
#
# Strategy: Use FP4 quantization for inference, FP16 for training
# =============================================================================

tflops_budget:
  # Raw compute available
  total_fp4: 2070.0
  total_fp8: 275.0
  total_fp16: 137.0
  total_fp32: 68.0

  # Utilization targets
  safe_utilization: 0.85
  burst_utilization: 0.95

  # ==========================================================================
  # FP4/INT4 Quantized Inference Budget (Primary - 2070 TFLOPS available)
  # ==========================================================================
  # With FP4 quantization via TensorRT, we get ~15x more compute than FP16
  # This enables GIANT model variants and higher frequencies
  # ==========================================================================
  fp4_allocations:
    # Tier 1 - Safety (1kHz) - HIGHEST PRIORITY
    safety_vjepa2_giant: 150.0          # V-JEPA 2 Giant for collision prediction
    safety_detection_ensemble: 100.0    # Multi-model safety ensemble
    force_torque_prediction: 50.0       # Predictive force limiting

    # Tier 2 - Perception (200Hz) - DOUBLED FREQUENCY with FP4
    dinov3_vit_giant: 120.0             # DINOv3 ViT-G (was ViT-L at 8 FP16)
    sam3_huge: 200.0                    # SAM3 Huge (was Large at 15 FP16)
    depth_anything_v3_large: 80.0       # Depth Anything V3 Large
    rtmpose_x_wholebody: 60.0           # RTMPose-X 133 keypoints
    multi_view_fusion: 40.0             # 8-camera fusion network

    # Tier 2 - Action (200Hz)
    pi0_vla_large: 150.0                # Pi0 VLA Large (was 10 FP16)
    openvla_7b_quantized: 200.0         # OpenVLA 7B INT4 quantized
    action_chunking_transformer: 80.0   # ACT for smooth trajectories

    # Tier 2 - World Modeling (100Hz)
    vjepa2_giant_world: 180.0           # V-JEPA 2 Giant world model
    physics_prediction: 60.0            # Physics-informed prediction
    object_dynamics: 40.0               # Object motion prediction

    # Tier 2 - Enhanced Safety Redundancy (reallocated from LLM)
    safety_backup_model: 100.0          # Redundant safety model
    tactile_prediction: 50.0            # Tactile sensor prediction
    human_intent_prediction: 100.0      # Predict human movement for HRI safety

    # Tier 3 - Learning (10Hz)
    il_training_accelerated: 100.0      # Faster IL with FP4 forward pass
    moai_compression: 30.0              # MOAI gradient compression
    skill_distillation: 40.0            # Online skill distillation

    # Tier 4 - Background Tasks
    anomaly_detection_ensemble: 50.0    # Multi-model anomaly detection
    spatial_brain_enhanced: 40.0        # Enhanced spatial reasoning
    fhe_acceleration: 10.0              # FHE helper computations

    # Reserve for burst/new capabilities
    reserve: 90.0

    # TOTAL: 2070.0 TFLOPS (100% FP4 utilization)

  # ==========================================================================
  # FP16 Training Budget (Secondary - 137 TFLOPS available)
  # ==========================================================================
  # Used for gradient computation and model updates (requires higher precision)
  # ==========================================================================
  fp16_allocations:
    # Online learning requires FP16 precision
    gradient_computation: 60.0
    batch_normalization: 15.0
    optimizer_step: 20.0
    loss_computation: 10.0
    validation: 15.0
    # Headroom for training spikes
    training_reserve: 17.0
    # TOTAL: 137.0 TFLOPS (100% FP16 for training)

pipeline:
  queues:
    safety_maxsize: 100
    perception_maxsize: 500
    learning_maxsize: 1000
  routing:
    safety_cameras: [0, 1, 2, 3]
    perception_cameras: [4, 5, 6, 7]
  learning:
    batch_size: 1000
    batch_timeout: 60.0

retargeting:
  workspace_min: [-1.0, -1.0, 0.0]
  workspace_max: [1.0, 1.0, 1.5]
  max_joint_velocity: 1.0
  ik:
    max_position_error: 0.05
    max_rotation_error: 0.2
    fallback_to_previous: true

# =============================================================================
# Glove Input Configuration
# =============================================================================
glove:
  # Glove type selection: auto, dyglove, manus, simulator
  type: "auto"                             # auto-detects available hardware

  # Hand configuration
  hands:
    left_enabled: true
    right_enabled: true

  # Update rate (Hz)
  update_rate: 120.0

  # DYGlove-specific settings (WiFi 6E connection)
  dyglove:
    wifi_ip: "192.168.4.1"
    wifi_port: 8080
    battery_low_threshold: 20
    enable_haptics: true
    haptic_intensity: 0.7

  # MANUS Glove-specific settings
  manus:
    sdk_library_path: "/usr/local/lib/libManusSdk.so"
    enable_haptics: true
    haptic_intensity: 0.7
    # Profile: default, precision, gaming
    profile: "precision"

  # Simulator settings (for testing without hardware)
  simulator:
    noise_level: 0.01
    simulate_latency: false
    latency_ms: 5.0

# =============================================================================
# Meta AI Models Configuration
# =============================================================================
meta_ai:
  # ==========================================================================
  # Quantization Settings (FP4/INT4 via TensorRT)
  # ==========================================================================
  quantization:
    enabled: true
    precision: "fp4"                   # fp4, fp8, fp16, fp32
    calibration_samples: 1000
    tensorrt_workspace_gb: 16
    use_dynamic_quantization: true
    cache_quantized_models: true

  # ==========================================================================
  # DINOv3 Vision Encoder - GIANT variant with FP4
  # ==========================================================================
  dinov3:
    enabled: true
    model_size: "vit_giant"            # UPGRADED: vit_giant (was vit_large)
    input_size: 518
    precision: "fp4"                   # FP4 quantized inference
    use_fp16: false                    # Disabled - using FP4
    batch_size: 4                      # Multi-frame batching
    cache_dir: "/var/lib/dynamical/models/dinov3"

  # ==========================================================================
  # SAM3 Segmentation - HUGE variant with FP4
  # ==========================================================================
  sam3:
    enabled: true
    model_size: "sam3_huge"            # UPGRADED: sam3_huge (was sam3_large)
    input_size: 1024
    precision: "fp4"                   # FP4 quantized inference
    max_objects: 20                    # Increased capacity
    confidence_threshold: 0.5
    enable_tracking: true
    enable_video_mode: true            # SAM3 video segmentation
    cache_dir: "/var/lib/dynamical/models/sam3"

  # ==========================================================================
  # V-JEPA 2 World Model - GIANT variant with FP4
  # ==========================================================================
  vjepa2:
    enabled: true
    model_size: "vjepa2_giant"         # UPGRADED: vjepa2_giant (was vjepa2_large)
    precision: "fp4"                   # FP4 quantized inference
    num_frames: 32                     # Increased from 16
    prediction_horizon: 32             # Increased from 16
    enable_safety_prediction: true
    enable_action_conditioning: true   # V-JEPA 2-AC variant
    collision_threshold: 0.7
    emergency_stop_threshold: 0.9
    cache_dir: "/var/lib/dynamical/models/vjepa2"

  # ==========================================================================
  # Privacy settings (N2HE encryption)
  # ==========================================================================
  privacy:
    enabled: true
    security_bits: 128
    lwe_dimension: 1024
    enable_homomorphic_routing: true

  # ==========================================================================
  # Unified pipeline settings - UPGRADED frequencies with FP4
  # ==========================================================================
  pipeline:
    fusion_method: "attention"         # UPGRADED: attention fusion (was concat)
    safety_rate_hz: 1000.0             # Safety tier (V-JEPA 2 collision prediction)
    control_rate_hz: 200.0             # UPGRADED: 200Hz (was 100Hz)
    perception_rate_hz: 200.0          # UPGRADED: 200Hz (was 100Hz)
    learning_rate_hz: 10.0             # Learning tier (skill updates)
    cloud_rate_hz: 0.1                 # Cloud tier (federated sync)

  # ==========================================================================
  # TFLOPS allocation for Meta AI models (FP4)
  # ==========================================================================
  tflops_allocation:
    # Giant variants with FP4 quantization
    dinov3_giant: 120.0                # ViT-G FP4 (was 8.0 FP16 ViT-L)
    sam3_huge: 200.0                   # SAM3 Huge FP4 (was 15.0 FP16 Large)
    vjepa2_giant: 330.0                # V-JEPA 2 Giant FP4 (was 10.0 FP16 Large)
    # Total Meta AI: 650.0 TFLOPS (31% of FP4 budget)
    # Remaining 250 TFLOPS reallocated to safety redundancy
    total: 650.0

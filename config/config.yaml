# Dynamical Edge System Configuration

system:
  simulation_mode: false
  log_level: "INFO"

safety:
  stop_dist: 1.5
  sensitivity: 0.8

cameras:
  rtsp_url: "rtsp://192.168.1.100:554/stream"
  
models:
  paligemma_path: "models/paligemma"

# =============================================================================
# Compute Budget - Jetson Thor (Blackwell Architecture)
# =============================================================================
# Peak Compute by Precision:
#   FP4/INT4:  2070 TFLOPS (quantized inference)
#   FP8:       275 TFLOPS  (mixed precision)
#   FP16:      137 TFLOPS  (half precision)
#   FP32:      68 TFLOPS   (full precision)
#
# Strategy: Use FP4 quantization for inference, FP16 for training
# =============================================================================

tflops_budget:
  # Raw compute available
  total_fp4: 2070.0
  total_fp8: 275.0
  total_fp16: 137.0
  total_fp32: 68.0

  # Utilization targets
  safe_utilization: 0.85
  burst_utilization: 0.95

  # ==========================================================================
  # FP4/INT4 Compute Model - DYNAMIC SCALING
  # ==========================================================================
  # Compute scales with: cameras, gloves, concurrent skills
  # Fixed allocations for safety, dynamic for peripherals
  # ==========================================================================

  # ---------------------------------------------------------------------------
  # FIXED ALLOCATIONS (always reserved, regardless of peripherals)
  # ---------------------------------------------------------------------------
  fixed_allocations:
    # Tier 1 - Safety (1kHz) - NEVER REDUCED
    safety_vjepa2_giant: 150.0          # V-JEPA 2 Giant collision prediction
    safety_detection_ensemble: 100.0    # Multi-model safety ensemble
    safety_backup_model: 100.0          # Redundant safety model
    force_torque_prediction: 50.0       # Predictive force limiting
    # Safety subtotal: 400.0 TFLOPS (fixed)

    # Core action models (always loaded)
    pi0_vla_base: 50.0                  # Base VLA always available
    action_chunking_base: 30.0          # Base ACT always available
    # Core action subtotal: 80.0 TFLOPS (fixed)

    # Learning (10Hz) - runs continuously
    il_training: 100.0
    moai_compression: 30.0
    skill_distillation: 40.0
    # Learning subtotal: 170.0 TFLOPS (fixed)

    # Background
    anomaly_detection: 50.0
    spatial_brain: 40.0
    fhe_acceleration: 10.0
    # Background subtotal: 100.0 TFLOPS (fixed)

    # FIXED TOTAL: 750.0 TFLOPS
    total_fixed: 750.0

  # ---------------------------------------------------------------------------
  # PER-CAMERA ALLOCATION (scales with number of ONVIF cameras)
  # ---------------------------------------------------------------------------
  per_camera_tflops:
    dinov3_per_camera: 15.0             # DINOv3 ViT-G per camera @ 200Hz
    sam3_per_camera: 25.0               # SAM3 Huge per camera @ 200Hz
    depth_per_camera: 10.0              # Depth Anything V3 per camera
    pose_per_camera: 7.5                # RTMPose-X per camera
    fusion_per_camera: 2.5              # Multi-view fusion contribution
    # TOTAL PER CAMERA: 60.0 TFLOPS

  # ---------------------------------------------------------------------------
  # PER-GLOVE ALLOCATION (scales with number of gloves)
  # ---------------------------------------------------------------------------
  per_glove_tflops:
    retargeting_per_glove: 15.0         # Hand retargeting @ 120Hz
    haptic_prediction: 5.0              # Haptic feedback prediction
    grasp_planning: 10.0                # Per-hand grasp planning
    # TOTAL PER GLOVE: 30.0 TFLOPS

  # ---------------------------------------------------------------------------
  # PER-SKILL ALLOCATION (scales with concurrent skills)
  # ---------------------------------------------------------------------------
  per_skill_tflops:
    skill_expert_base: 20.0             # Base skill expert inference
    skill_expert_large: 50.0            # Large skill (manipulation)
    skill_blending: 5.0                 # MoE blending overhead per skill
    # Skills use pool from remaining compute

  # ---------------------------------------------------------------------------
  # VLA SCALING (for complex tasks)
  # ---------------------------------------------------------------------------
  vla_scaling:
    openvla_7b_increment: 150.0         # Full OpenVLA 7B when needed
    world_model_increment: 100.0        # V-JEPA 2 world model boost
    physics_prediction: 60.0            # Physics-informed prediction
    human_intent: 50.0                  # Human intent prediction for HRI

  # ---------------------------------------------------------------------------
  # DYNAMIC POOL CALCULATION
  # ---------------------------------------------------------------------------
  # Available = 2070 - fixed (750) = 1320 TFLOPS for scaling
  #
  # Example configurations:
  #   8 cameras + 2 gloves + 4 skills:
  #     Cameras: 8 × 60 = 480 TFLOPS
  #     Gloves:  2 × 30 = 60 TFLOPS
  #     Skills:  4 × 25 = 100 TFLOPS (avg)
  #     VLA boost: 150 TFLOPS
  #     World model: 100 TFLOPS
  #     Human intent: 50 TFLOPS
  #     Total dynamic: 940 TFLOPS
  #     Remaining: 380 TFLOPS reserve
  #
  #   16 cameras + 4 gloves + 8 skills:
  #     Cameras: 16 × 60 = 960 TFLOPS
  #     Gloves:  4 × 30 = 120 TFLOPS
  #     Skills:  8 × 25 = 200 TFLOPS
  #     Total dynamic: 1280 TFLOPS
  #     Remaining: 40 TFLOPS reserve (near limit!)
  # ---------------------------------------------------------------------------

  # Maximum peripherals per Jetson Thor
  max_peripherals:
    max_cameras: 22                     # (2070-750) / 60 = 22 cameras max
    max_gloves: 4                       # 2 pairs (left+right each)
    max_concurrent_skills: 10           # Practical limit for blending
    recommended_cameras: 12             # For comfortable headroom
    recommended_gloves: 2               # 1 pair typical

  # ==========================================================================
  # FP16 Training Budget (Secondary - 137 TFLOPS available)
  # ==========================================================================
  # Used for gradient computation and model updates (requires higher precision)
  # ==========================================================================
  fp16_allocations:
    # Online learning requires FP16 precision
    gradient_computation: 60.0
    batch_normalization: 15.0
    optimizer_step: 20.0
    loss_computation: 10.0
    validation: 15.0
    # Headroom for training spikes
    training_reserve: 17.0
    # TOTAL: 137.0 TFLOPS (100% FP16 for training)

pipeline:
  queues:
    safety_maxsize: 100
    perception_maxsize: 500
    learning_maxsize: 1000
  routing:
    safety_cameras: [0, 1, 2, 3]
    perception_cameras: [4, 5, 6, 7]
  learning:
    batch_size: 1000
    batch_timeout: 60.0

retargeting:
  workspace_min: [-1.0, -1.0, 0.0]
  workspace_max: [1.0, 1.0, 1.5]
  max_joint_velocity: 1.0
  ik:
    max_position_error: 0.05
    max_rotation_error: 0.2
    fallback_to_previous: true

# =============================================================================
# Glove Input Configuration
# =============================================================================
glove:
  # Glove type selection: auto, dyglove, manus, simulator
  type: "auto"                             # auto-detects available hardware

  # Hand configuration
  hands:
    left_enabled: true
    right_enabled: true

  # Update rate (Hz)
  update_rate: 120.0

  # DYGlove-specific settings (WiFi 6E connection)
  dyglove:
    wifi_ip: "192.168.4.1"
    wifi_port: 8080
    battery_low_threshold: 20
    enable_haptics: true
    haptic_intensity: 0.7

  # MANUS Glove-specific settings
  manus:
    sdk_library_path: "/usr/local/lib/libManusSdk.so"
    enable_haptics: true
    haptic_intensity: 0.7
    # Profile: default, precision, gaming
    profile: "precision"

  # Simulator settings (for testing without hardware)
  simulator:
    noise_level: 0.01
    simulate_latency: false
    latency_ms: 5.0

# =============================================================================
# Meta AI Models Configuration
# =============================================================================
meta_ai:
  # ==========================================================================
  # Quantization Settings (FP4/INT4 via TensorRT)
  # ==========================================================================
  quantization:
    enabled: true
    precision: "fp4"                   # fp4, fp8, fp16, fp32
    calibration_samples: 1000
    tensorrt_workspace_gb: 16
    use_dynamic_quantization: true
    cache_quantized_models: true

  # ==========================================================================
  # DINOv3 Vision Encoder - GIANT variant with FP4
  # ==========================================================================
  dinov3:
    enabled: true
    model_size: "vit_giant"            # UPGRADED: vit_giant (was vit_large)
    input_size: 518
    precision: "fp4"                   # FP4 quantized inference
    use_fp16: false                    # Disabled - using FP4
    batch_size: 4                      # Multi-frame batching
    cache_dir: "/var/lib/dynamical/models/dinov3"

  # ==========================================================================
  # SAM3 Segmentation - HUGE variant with FP4
  # ==========================================================================
  sam3:
    enabled: true
    model_size: "sam3_huge"            # UPGRADED: sam3_huge (was sam3_large)
    input_size: 1024
    precision: "fp4"                   # FP4 quantized inference
    max_objects: 20                    # Increased capacity
    confidence_threshold: 0.5
    enable_tracking: true
    enable_video_mode: true            # SAM3 video segmentation
    cache_dir: "/var/lib/dynamical/models/sam3"

  # ==========================================================================
  # V-JEPA 2 World Model - GIANT variant with FP4
  # ==========================================================================
  vjepa2:
    enabled: true
    model_size: "vjepa2_giant"         # UPGRADED: vjepa2_giant (was vjepa2_large)
    precision: "fp4"                   # FP4 quantized inference
    num_frames: 32                     # Increased from 16
    prediction_horizon: 32             # Increased from 16
    enable_safety_prediction: true
    enable_action_conditioning: true   # V-JEPA 2-AC variant
    collision_threshold: 0.7
    emergency_stop_threshold: 0.9
    cache_dir: "/var/lib/dynamical/models/vjepa2"

  # ==========================================================================
  # Privacy settings (N2HE encryption)
  # ==========================================================================
  privacy:
    enabled: true
    security_bits: 128
    lwe_dimension: 1024
    enable_homomorphic_routing: true

  # ==========================================================================
  # Unified pipeline settings - UPGRADED frequencies with FP4
  # ==========================================================================
  pipeline:
    fusion_method: "attention"         # UPGRADED: attention fusion (was concat)
    safety_rate_hz: 1000.0             # Safety tier (V-JEPA 2 collision prediction)
    control_rate_hz: 200.0             # UPGRADED: 200Hz (was 100Hz)
    perception_rate_hz: 200.0          # UPGRADED: 200Hz (was 100Hz)
    learning_rate_hz: 10.0             # Learning tier (skill updates)
    cloud_rate_hz: 0.1                 # Cloud tier (federated sync)

  # ==========================================================================
  # TFLOPS allocation for Meta AI models (FP4)
  # ==========================================================================
  tflops_allocation:
    # Giant variants with FP4 quantization
    dinov3_giant: 120.0                # ViT-G FP4 (was 8.0 FP16 ViT-L)
    sam3_huge: 200.0                   # SAM3 Huge FP4 (was 15.0 FP16 Large)
    vjepa2_giant: 330.0                # V-JEPA 2 Giant FP4 (was 10.0 FP16 Large)
    # Total Meta AI: 650.0 TFLOPS (31% of FP4 budget)
    # Remaining 250 TFLOPS reallocated to safety redundancy
    total: 650.0
